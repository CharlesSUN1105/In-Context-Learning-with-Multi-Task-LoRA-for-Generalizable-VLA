{
  "best_global_step": 675,
  "best_metric": 0.12365436553955078,
  "best_model_checkpoint": "/home/s84414554/qwen3_finetune/roboprompt-data/output/stack_cup_10shot/checkpoint-675",
  "epoch": 3.0,
  "eval_steps": 75,
  "global_step": 675,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.09970498085021973,
      "learning_rate": 9e-06,
      "loss": 0.3738,
      "step": 10
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.11567480117082596,
      "learning_rate": 1.9e-05,
      "loss": 0.3721,
      "step": 20
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.10920822620391846,
      "learning_rate": 2.9e-05,
      "loss": 0.3663,
      "step": 30
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.09934388101100922,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.347,
      "step": 40
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.08855331689119339,
      "learning_rate": 4.9e-05,
      "loss": 0.3228,
      "step": 50
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.07770991325378418,
      "learning_rate": 4.997442234802456e-05,
      "loss": 0.2932,
      "step": 60
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.062333844602108,
      "learning_rate": 4.988607296439458e-05,
      "loss": 0.2698,
      "step": 70
    },
    {
      "epoch": 0.3333333333333333,
      "eval_loss": 0.2517423629760742,
      "eval_runtime": 38.9852,
      "eval_samples_per_second": 5.13,
      "eval_steps_per_second": 0.641,
      "step": 75
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.060876138508319855,
      "learning_rate": 4.9734859200644905e-05,
      "loss": 0.2532,
      "step": 80
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.0752631202340126,
      "learning_rate": 4.952116303586631e-05,
      "loss": 0.2354,
      "step": 90
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.09397518634796143,
      "learning_rate": 4.9245524285117274e-05,
      "loss": 0.2196,
      "step": 100
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.07585914433002472,
      "learning_rate": 4.8908639235804324e-05,
      "loss": 0.1991,
      "step": 110
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.07316199690103531,
      "learning_rate": 4.851135888879958e-05,
      "loss": 0.1867,
      "step": 120
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.06269357353448868,
      "learning_rate": 4.805468680873874e-05,
      "loss": 0.1755,
      "step": 130
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.06428886204957962,
      "learning_rate": 4.753977658892967e-05,
      "loss": 0.1688,
      "step": 140
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.08285053074359894,
      "learning_rate": 4.696792893727562e-05,
      "loss": 0.1672,
      "step": 150
    },
    {
      "epoch": 0.6666666666666666,
      "eval_loss": 0.1634596586227417,
      "eval_runtime": 38.9849,
      "eval_samples_per_second": 5.13,
      "eval_steps_per_second": 0.641,
      "step": 150
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.09052464365959167,
      "learning_rate": 4.634058839057417e-05,
      "loss": 0.164,
      "step": 160
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.09979084879159927,
      "learning_rate": 4.565933966549189e-05,
      "loss": 0.1594,
      "step": 170
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.08791080117225647,
      "learning_rate": 4.492590365543253e-05,
      "loss": 0.1556,
      "step": 180
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.0909099355340004,
      "learning_rate": 4.414213308341092e-05,
      "loss": 0.1532,
      "step": 190
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.10120747983455658,
      "learning_rate": 4.3310007821913836e-05,
      "loss": 0.1503,
      "step": 200
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.11427020281553268,
      "learning_rate": 4.2431629891570266e-05,
      "loss": 0.1476,
      "step": 210
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.14114834368228912,
      "learning_rate": 4.150921815126493e-05,
      "loss": 0.1428,
      "step": 220
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.14238138496875763,
      "eval_runtime": 39.0044,
      "eval_samples_per_second": 5.128,
      "eval_steps_per_second": 0.641,
      "step": 225
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.11658881604671478,
      "learning_rate": 4.054510269310803e-05,
      "loss": 0.1439,
      "step": 230
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.11786074936389923,
      "learning_rate": 3.954171895642052e-05,
      "loss": 0.1414,
      "step": 240
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.1429140865802765,
      "learning_rate": 3.85016015756029e-05,
      "loss": 0.1392,
      "step": 250
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.1530463844537735,
      "learning_rate": 3.742737797742878e-05,
      "loss": 0.1389,
      "step": 260
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.171298086643219,
      "learning_rate": 3.632176174393682e-05,
      "loss": 0.1365,
      "step": 270
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.1321035474538803,
      "learning_rate": 3.5187545757687015e-05,
      "loss": 0.136,
      "step": 280
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.14645534753799438,
      "learning_rate": 3.402759514669694e-05,
      "loss": 0.1354,
      "step": 290
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.1658690720796585,
      "learning_rate": 3.2844840046879686e-05,
      "loss": 0.134,
      "step": 300
    },
    {
      "epoch": 1.3333333333333333,
      "eval_loss": 0.13369852304458618,
      "eval_runtime": 38.9997,
      "eval_samples_per_second": 5.128,
      "eval_steps_per_second": 0.641,
      "step": 300
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 0.14924141764640808,
      "learning_rate": 3.1642268200266317e-05,
      "loss": 0.1332,
      "step": 310
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.19729478657245636,
      "learning_rate": 3.0422917407710137e-05,
      "loss": 0.1325,
      "step": 320
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.17489562928676605,
      "learning_rate": 2.9189867855138103e-05,
      "loss": 0.1333,
      "step": 330
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.132522851228714,
      "learning_rate": 2.79462343327339e-05,
      "loss": 0.1324,
      "step": 340
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.14095185697078705,
      "learning_rate": 2.6695158366707522e-05,
      "loss": 0.1316,
      "step": 350
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.15801003575325012,
      "learning_rate": 2.5439800283527494e-05,
      "loss": 0.1318,
      "step": 360
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 0.1625242829322815,
      "learning_rate": 2.418333122666191e-05,
      "loss": 0.1306,
      "step": 370
    },
    {
      "epoch": 1.6666666666666665,
      "eval_loss": 0.1298687756061554,
      "eval_runtime": 39.0018,
      "eval_samples_per_second": 5.128,
      "eval_steps_per_second": 0.641,
      "step": 375
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.170051708817482,
      "learning_rate": 2.2928925145994794e-05,
      "loss": 0.1304,
      "step": 380
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.2004205286502838,
      "learning_rate": 2.1679750780153267e-05,
      "loss": 0.1302,
      "step": 390
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.14765223860740662,
      "learning_rate": 2.0438963651998747e-05,
      "loss": 0.1306,
      "step": 400
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.17706099152565002,
      "learning_rate": 1.920969809750234e-05,
      "loss": 0.1293,
      "step": 410
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.18027648329734802,
      "learning_rate": 1.7995059348140165e-05,
      "loss": 0.128,
      "step": 420
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.17235824465751648,
      "learning_rate": 1.6798115686809125e-05,
      "loss": 0.1272,
      "step": 430
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.16949307918548584,
      "learning_rate": 1.562189069707807e-05,
      "loss": 0.1275,
      "step": 440
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.22491177916526794,
      "learning_rate": 1.4469355625353198e-05,
      "loss": 0.1275,
      "step": 450
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.12668995559215546,
      "eval_runtime": 38.9684,
      "eval_samples_per_second": 5.132,
      "eval_steps_per_second": 0.642,
      "step": 450
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 0.19579049944877625,
      "learning_rate": 1.3343421875251888e-05,
      "loss": 0.1262,
      "step": 460
    },
    {
      "epoch": 2.088888888888889,
      "grad_norm": 0.24954518675804138,
      "learning_rate": 1.2246933653144385e-05,
      "loss": 0.1259,
      "step": 470
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.1893448531627655,
      "learning_rate": 1.1182660783441718e-05,
      "loss": 0.1255,
      "step": 480
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 0.213567316532135,
      "learning_rate": 1.0153291711778826e-05,
      "loss": 0.1253,
      "step": 490
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.20846886932849884,
      "learning_rate": 9.161426713767574e-06,
      "loss": 0.1252,
      "step": 500
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 0.1667061597108841,
      "learning_rate": 8.209571326474896e-06,
      "loss": 0.1249,
      "step": 510
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 0.20022141933441162,
      "learning_rate": 7.300130019218687e-06,
      "loss": 0.1243,
      "step": 520
    },
    {
      "epoch": 2.3333333333333335,
      "eval_loss": 0.12472216784954071,
      "eval_runtime": 38.9986,
      "eval_samples_per_second": 5.128,
      "eval_steps_per_second": 0.641,
      "step": 525
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 0.18207921087741852,
      "learning_rate": 6.435400119669618e-06,
      "loss": 0.124,
      "step": 530
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.1819992959499359,
      "learning_rate": 5.617566010602113e-06,
      "loss": 0.125,
      "step": 540
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.21905706822872162,
      "learning_rate": 4.848693611953825e-06,
      "loss": 0.1244,
      "step": 550
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 0.1828455626964569,
      "learning_rate": 4.130725162132612e-06,
      "loss": 0.1251,
      "step": 560
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.206602081656456,
      "learning_rate": 3.4654743117537524e-06,
      "loss": 0.124,
      "step": 570
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 0.18025746941566467,
      "learning_rate": 2.8546215422010638e-06,
      "loss": 0.1238,
      "step": 580
    },
    {
      "epoch": 2.6222222222222222,
      "grad_norm": 0.21644991636276245,
      "learning_rate": 2.299709920585108e-06,
      "loss": 0.1242,
      "step": 590
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.19579248130321503,
      "learning_rate": 1.802141201821736e-06,
      "loss": 0.1251,
      "step": 600
    },
    {
      "epoch": 2.6666666666666665,
      "eval_loss": 0.12375140935182571,
      "eval_runtime": 39.0005,
      "eval_samples_per_second": 5.128,
      "eval_steps_per_second": 0.641,
      "step": 600
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 0.18424148857593536,
      "learning_rate": 1.3631722876775138e-06,
      "loss": 0.1233,
      "step": 610
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 0.20106983184814453,
      "learning_rate": 9.839120517267985e-07,
      "loss": 0.1236,
      "step": 620
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.1828472912311554,
      "learning_rate": 6.653185382408194e-07,
      "loss": 0.1234,
      "step": 630
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 0.20910599827766418,
      "learning_rate": 4.0819654208472947e-07,
      "loss": 0.1238,
      "step": 640
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.17022183537483215,
      "learning_rate": 2.1319557573591108e-07,
      "loss": 0.1243,
      "step": 650
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.1907314956188202,
      "learning_rate": 8.080822855909831e-08,
      "loss": 0.124,
      "step": 660
    },
    {
      "epoch": 2.977777777777778,
      "grad_norm": 0.1923471838235855,
      "learning_rate": 1.136892248288779e-08,
      "loss": 0.1239,
      "step": 670
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.12365436553955078,
      "eval_runtime": 39.0028,
      "eval_samples_per_second": 5.128,
      "eval_steps_per_second": 0.641,
      "step": 675
    }
  ],
  "logging_steps": 10,
  "max_steps": 675,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 75,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.832259989504e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
