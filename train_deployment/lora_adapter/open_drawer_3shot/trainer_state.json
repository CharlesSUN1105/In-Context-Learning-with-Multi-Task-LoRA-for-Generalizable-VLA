{
  "best_global_step": 672,
  "best_metric": 0.11423914134502411,
  "best_model_checkpoint": "/home/s84414554/qwen3_finetune/roboprompt-data/output/open_drawer_3shot/checkpoint-672",
  "epoch": 3.0,
  "eval_steps": 56,
  "global_step": 675,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.37193116545677185,
      "learning_rate": 9e-06,
      "loss": 1.2511,
      "step": 10
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.4234808683395386,
      "learning_rate": 1.9e-05,
      "loss": 1.2464,
      "step": 20
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.47001081705093384,
      "learning_rate": 2.9e-05,
      "loss": 1.2139,
      "step": 30
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.5115689635276794,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.1218,
      "step": 40
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.5128622651100159,
      "learning_rate": 4.9e-05,
      "loss": 0.9745,
      "step": 50
    },
    {
      "epoch": 0.24888888888888888,
      "eval_loss": 0.7713569402694702,
      "eval_runtime": 14.2023,
      "eval_samples_per_second": 14.082,
      "eval_steps_per_second": 1.76,
      "step": 56
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.34151726961135864,
      "learning_rate": 4.997442234802456e-05,
      "loss": 0.7972,
      "step": 60
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.33550500869750977,
      "learning_rate": 4.988607296439458e-05,
      "loss": 0.6826,
      "step": 70
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.4359758496284485,
      "learning_rate": 4.9734859200644905e-05,
      "loss": 0.5786,
      "step": 80
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5014514327049255,
      "learning_rate": 4.952116303586631e-05,
      "loss": 0.4443,
      "step": 90
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.35913485288619995,
      "learning_rate": 4.9245524285117274e-05,
      "loss": 0.3316,
      "step": 100
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.4247080385684967,
      "learning_rate": 4.8908639235804324e-05,
      "loss": 0.277,
      "step": 110
    },
    {
      "epoch": 0.49777777777777776,
      "eval_loss": 0.25132399797439575,
      "eval_runtime": 14.2146,
      "eval_samples_per_second": 14.07,
      "eval_steps_per_second": 1.759,
      "step": 112
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.4072485864162445,
      "learning_rate": 4.851135888879958e-05,
      "loss": 0.2448,
      "step": 120
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.3768521547317505,
      "learning_rate": 4.805468680873874e-05,
      "loss": 0.2193,
      "step": 130
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.3013063669204712,
      "learning_rate": 4.753977658892967e-05,
      "loss": 0.2031,
      "step": 140
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.49639540910720825,
      "learning_rate": 4.696792893727562e-05,
      "loss": 0.1964,
      "step": 150
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.3679688274860382,
      "learning_rate": 4.634058839057417e-05,
      "loss": 0.174,
      "step": 160
    },
    {
      "epoch": 0.7466666666666667,
      "eval_loss": 0.16293135285377502,
      "eval_runtime": 14.15,
      "eval_samples_per_second": 14.134,
      "eval_steps_per_second": 1.767,
      "step": 168
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.28716036677360535,
      "learning_rate": 4.565933966549189e-05,
      "loss": 0.1644,
      "step": 170
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3578498661518097,
      "learning_rate": 4.492590365543253e-05,
      "loss": 0.1623,
      "step": 180
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.37854307889938354,
      "learning_rate": 4.414213308341092e-05,
      "loss": 0.1577,
      "step": 190
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.27671918272972107,
      "learning_rate": 4.3310007821913836e-05,
      "loss": 0.1551,
      "step": 200
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.2520013749599457,
      "learning_rate": 4.2431629891570266e-05,
      "loss": 0.1546,
      "step": 210
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.3094639480113983,
      "learning_rate": 4.150921815126493e-05,
      "loss": 0.1539,
      "step": 220
    },
    {
      "epoch": 0.9955555555555555,
      "eval_loss": 0.14887122809886932,
      "eval_runtime": 14.2432,
      "eval_samples_per_second": 14.042,
      "eval_steps_per_second": 1.755,
      "step": 224
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.35324329137802124,
      "learning_rate": 4.054510269310803e-05,
      "loss": 0.1468,
      "step": 230
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.36293143033981323,
      "learning_rate": 3.954171895642052e-05,
      "loss": 0.1487,
      "step": 240
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.31101083755493164,
      "learning_rate": 3.85016015756029e-05,
      "loss": 0.1476,
      "step": 250
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.3155261278152466,
      "learning_rate": 3.742737797742878e-05,
      "loss": 0.1411,
      "step": 260
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.33444273471832275,
      "learning_rate": 3.632176174393682e-05,
      "loss": 0.1463,
      "step": 270
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.43710342049598694,
      "learning_rate": 3.5187545757687015e-05,
      "loss": 0.1424,
      "step": 280
    },
    {
      "epoch": 1.2444444444444445,
      "eval_loss": 0.14113132655620575,
      "eval_runtime": 14.2304,
      "eval_samples_per_second": 14.054,
      "eval_steps_per_second": 1.757,
      "step": 280
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.30932480096817017,
      "learning_rate": 3.402759514669694e-05,
      "loss": 0.1464,
      "step": 290
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.28818202018737793,
      "learning_rate": 3.2844840046879686e-05,
      "loss": 0.1402,
      "step": 300
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 0.3124678134918213,
      "learning_rate": 3.1642268200266317e-05,
      "loss": 0.1345,
      "step": 310
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.43154045939445496,
      "learning_rate": 3.0422917407710137e-05,
      "loss": 0.134,
      "step": 320
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.3665522634983063,
      "learning_rate": 2.9189867855138103e-05,
      "loss": 0.1318,
      "step": 330
    },
    {
      "epoch": 1.4933333333333334,
      "eval_loss": 0.12591834366321564,
      "eval_runtime": 14.2148,
      "eval_samples_per_second": 14.07,
      "eval_steps_per_second": 1.759,
      "step": 336
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.38729217648506165,
      "learning_rate": 2.79462343327339e-05,
      "loss": 0.1273,
      "step": 340
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.35904020071029663,
      "learning_rate": 2.6695158366707522e-05,
      "loss": 0.1268,
      "step": 350
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.34632208943367004,
      "learning_rate": 2.5439800283527494e-05,
      "loss": 0.1228,
      "step": 360
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 0.369659423828125,
      "learning_rate": 2.418333122666191e-05,
      "loss": 0.1225,
      "step": 370
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.30447375774383545,
      "learning_rate": 2.2928925145994794e-05,
      "loss": 0.1188,
      "step": 380
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.3287753760814667,
      "learning_rate": 2.1679750780153267e-05,
      "loss": 0.1191,
      "step": 390
    },
    {
      "epoch": 1.7422222222222223,
      "eval_loss": 0.11812295764684677,
      "eval_runtime": 14.223,
      "eval_samples_per_second": 14.062,
      "eval_steps_per_second": 1.758,
      "step": 392
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.35533440113067627,
      "learning_rate": 2.0438963651998747e-05,
      "loss": 0.1181,
      "step": 400
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.3658607602119446,
      "learning_rate": 1.920969809750234e-05,
      "loss": 0.1166,
      "step": 410
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.3283427655696869,
      "learning_rate": 1.7995059348140165e-05,
      "loss": 0.1167,
      "step": 420
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.35330432653427124,
      "learning_rate": 1.6798115686809125e-05,
      "loss": 0.1177,
      "step": 430
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.3613075315952301,
      "learning_rate": 1.562189069707807e-05,
      "loss": 0.1191,
      "step": 440
    },
    {
      "epoch": 1.991111111111111,
      "eval_loss": 0.11643695831298828,
      "eval_runtime": 14.2161,
      "eval_samples_per_second": 14.069,
      "eval_steps_per_second": 1.759,
      "step": 448
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4896659851074219,
      "learning_rate": 1.4469355625353198e-05,
      "loss": 0.1147,
      "step": 450
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 0.34205004572868347,
      "learning_rate": 1.3343421875251888e-05,
      "loss": 0.1177,
      "step": 460
    },
    {
      "epoch": 2.088888888888889,
      "grad_norm": 0.3407983183860779,
      "learning_rate": 1.2246933653144385e-05,
      "loss": 0.1158,
      "step": 470
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.3575061559677124,
      "learning_rate": 1.1182660783441718e-05,
      "loss": 0.1147,
      "step": 480
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 0.34386318922042847,
      "learning_rate": 1.0153291711778826e-05,
      "loss": 0.1176,
      "step": 490
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.35816678404808044,
      "learning_rate": 9.161426713767574e-06,
      "loss": 0.1161,
      "step": 500
    },
    {
      "epoch": 2.24,
      "eval_loss": 0.11497070640325546,
      "eval_runtime": 14.2279,
      "eval_samples_per_second": 14.057,
      "eval_steps_per_second": 1.757,
      "step": 504
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 0.3518807590007782,
      "learning_rate": 8.209571326474896e-06,
      "loss": 0.1161,
      "step": 510
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 0.3841407001018524,
      "learning_rate": 7.300130019218687e-06,
      "loss": 0.1154,
      "step": 520
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 0.38379648327827454,
      "learning_rate": 6.435400119669618e-06,
      "loss": 0.1142,
      "step": 530
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.3475634753704071,
      "learning_rate": 5.617566010602113e-06,
      "loss": 0.1135,
      "step": 540
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.41946882009506226,
      "learning_rate": 4.848693611953825e-06,
      "loss": 0.1118,
      "step": 550
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 0.41243481636047363,
      "learning_rate": 4.130725162132612e-06,
      "loss": 0.1156,
      "step": 560
    },
    {
      "epoch": 2.488888888888889,
      "eval_loss": 0.11446638405323029,
      "eval_runtime": 14.2543,
      "eval_samples_per_second": 14.031,
      "eval_steps_per_second": 1.754,
      "step": 560
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.4105125963687897,
      "learning_rate": 3.4654743117537524e-06,
      "loss": 0.1107,
      "step": 570
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 0.3673967719078064,
      "learning_rate": 2.8546215422010638e-06,
      "loss": 0.1153,
      "step": 580
    },
    {
      "epoch": 2.6222222222222222,
      "grad_norm": 0.4009076654911041,
      "learning_rate": 2.299709920585108e-06,
      "loss": 0.116,
      "step": 590
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.5771808624267578,
      "learning_rate": 1.802141201821736e-06,
      "loss": 0.1127,
      "step": 600
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 0.3729301393032074,
      "learning_rate": 1.3631722876775138e-06,
      "loss": 0.1115,
      "step": 610
    },
    {
      "epoch": 2.7377777777777776,
      "eval_loss": 0.11427798122167587,
      "eval_runtime": 14.1479,
      "eval_samples_per_second": 14.136,
      "eval_steps_per_second": 1.767,
      "step": 616
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 0.40143901109695435,
      "learning_rate": 9.839120517267985e-07,
      "loss": 0.1127,
      "step": 620
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.35522541403770447,
      "learning_rate": 6.653185382408194e-07,
      "loss": 0.1159,
      "step": 630
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 0.3839974105358124,
      "learning_rate": 4.0819654208472947e-07,
      "loss": 0.1147,
      "step": 640
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.43100202083587646,
      "learning_rate": 2.1319557573591108e-07,
      "loss": 0.113,
      "step": 650
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.35321229696273804,
      "learning_rate": 8.080822855909831e-08,
      "loss": 0.1179,
      "step": 660
    },
    {
      "epoch": 2.977777777777778,
      "grad_norm": 0.36122167110443115,
      "learning_rate": 1.136892248288779e-08,
      "loss": 0.1144,
      "step": 670
    },
    {
      "epoch": 2.986666666666667,
      "eval_loss": 0.11423914134502411,
      "eval_runtime": 14.1907,
      "eval_samples_per_second": 14.094,
      "eval_steps_per_second": 1.762,
      "step": 672
    }
  ],
  "logging_steps": 10,
  "max_steps": 675,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 56,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.925448884224e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
