{
  "best_global_step": 525,
  "best_metric": 0.12678396701812744,
  "best_model_checkpoint": "/home/s84414554/qwen3_finetune/roboprompt-data/output/light_bulb_in_10shot/checkpoint-525",
  "epoch": 3.0,
  "eval_steps": 75,
  "global_step": 675,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.1306636929512024,
      "learning_rate": 9e-06,
      "loss": 0.4729,
      "step": 10
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.14883889257907867,
      "learning_rate": 1.9e-05,
      "loss": 0.473,
      "step": 20
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.17142777144908905,
      "learning_rate": 2.9e-05,
      "loss": 0.4645,
      "step": 30
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.14280037581920624,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.4383,
      "step": 40
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.12930689752101898,
      "learning_rate": 4.9e-05,
      "loss": 0.3986,
      "step": 50
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.10111474990844727,
      "learning_rate": 4.997442234802456e-05,
      "loss": 0.356,
      "step": 60
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.08362213522195816,
      "learning_rate": 4.988607296439458e-05,
      "loss": 0.3235,
      "step": 70
    },
    {
      "epoch": 0.3333333333333333,
      "eval_loss": 0.29391855001449585,
      "eval_runtime": 27.2178,
      "eval_samples_per_second": 7.275,
      "eval_steps_per_second": 0.919,
      "step": 75
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.08053497225046158,
      "learning_rate": 4.9734859200644905e-05,
      "loss": 0.298,
      "step": 80
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.08356352150440216,
      "learning_rate": 4.952116303586631e-05,
      "loss": 0.2777,
      "step": 90
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.10146894305944443,
      "learning_rate": 4.9245524285117274e-05,
      "loss": 0.2559,
      "step": 100
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.11342129111289978,
      "learning_rate": 4.8908639235804324e-05,
      "loss": 0.2275,
      "step": 110
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.1075645312666893,
      "learning_rate": 4.851135888879958e-05,
      "loss": 0.2028,
      "step": 120
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.1206156462430954,
      "learning_rate": 4.805468680873874e-05,
      "loss": 0.1881,
      "step": 130
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.1480475515127182,
      "learning_rate": 4.753977658892967e-05,
      "loss": 0.1756,
      "step": 140
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.13579554855823517,
      "learning_rate": 4.696792893727562e-05,
      "loss": 0.1674,
      "step": 150
    },
    {
      "epoch": 0.6666666666666666,
      "eval_loss": 0.1621975153684616,
      "eval_runtime": 27.2196,
      "eval_samples_per_second": 7.274,
      "eval_steps_per_second": 0.918,
      "step": 150
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.11205042153596878,
      "learning_rate": 4.634058839057417e-05,
      "loss": 0.1623,
      "step": 160
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.13126878440380096,
      "learning_rate": 4.565933966549189e-05,
      "loss": 0.1585,
      "step": 170
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1241823062300682,
      "learning_rate": 4.492590365543253e-05,
      "loss": 0.1525,
      "step": 180
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.12459329515695572,
      "learning_rate": 4.414213308341092e-05,
      "loss": 0.1487,
      "step": 190
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.14591844379901886,
      "learning_rate": 4.3310007821913836e-05,
      "loss": 0.1452,
      "step": 200
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.1305343210697174,
      "learning_rate": 4.2431629891570266e-05,
      "loss": 0.1435,
      "step": 210
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.1384541243314743,
      "learning_rate": 4.150921815126493e-05,
      "loss": 0.1415,
      "step": 220
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.13911914825439453,
      "eval_runtime": 27.2179,
      "eval_samples_per_second": 7.275,
      "eval_steps_per_second": 0.919,
      "step": 225
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.13735514879226685,
      "learning_rate": 4.054510269310803e-05,
      "loss": 0.1411,
      "step": 230
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.15254417061805725,
      "learning_rate": 3.954171895642052e-05,
      "loss": 0.1372,
      "step": 240
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.13837458193302155,
      "learning_rate": 3.85016015756029e-05,
      "loss": 0.1369,
      "step": 250
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.19032923877239227,
      "learning_rate": 3.742737797742878e-05,
      "loss": 0.1358,
      "step": 260
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.1697797030210495,
      "learning_rate": 3.632176174393682e-05,
      "loss": 0.1342,
      "step": 270
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.1607823520898819,
      "learning_rate": 3.5187545757687015e-05,
      "loss": 0.1318,
      "step": 280
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.16016007959842682,
      "learning_rate": 3.402759514669694e-05,
      "loss": 0.1315,
      "step": 290
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.17328056693077087,
      "learning_rate": 3.2844840046879686e-05,
      "loss": 0.13,
      "step": 300
    },
    {
      "epoch": 1.3333333333333333,
      "eval_loss": 0.13156922161579132,
      "eval_runtime": 27.1849,
      "eval_samples_per_second": 7.283,
      "eval_steps_per_second": 0.92,
      "step": 300
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 0.18369315564632416,
      "learning_rate": 3.1642268200266317e-05,
      "loss": 0.1309,
      "step": 310
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.21340800821781158,
      "learning_rate": 3.0422917407710137e-05,
      "loss": 0.1283,
      "step": 320
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.19669637084007263,
      "learning_rate": 2.9189867855138103e-05,
      "loss": 0.1277,
      "step": 330
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.21698994934558868,
      "learning_rate": 2.79462343327339e-05,
      "loss": 0.128,
      "step": 340
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.24224130809307098,
      "learning_rate": 2.6695158366707522e-05,
      "loss": 0.1254,
      "step": 350
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2262217253446579,
      "learning_rate": 2.5439800283527494e-05,
      "loss": 0.1265,
      "step": 360
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 0.19902190566062927,
      "learning_rate": 2.418333122666191e-05,
      "loss": 0.1243,
      "step": 370
    },
    {
      "epoch": 1.6666666666666665,
      "eval_loss": 0.1292826384305954,
      "eval_runtime": 27.2221,
      "eval_samples_per_second": 7.274,
      "eval_steps_per_second": 0.918,
      "step": 375
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.18978342413902283,
      "learning_rate": 2.2928925145994794e-05,
      "loss": 0.1251,
      "step": 380
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.21228212118148804,
      "learning_rate": 2.1679750780153267e-05,
      "loss": 0.1236,
      "step": 390
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.20320604741573334,
      "learning_rate": 2.0438963651998747e-05,
      "loss": 0.1239,
      "step": 400
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.1875523328781128,
      "learning_rate": 1.920969809750234e-05,
      "loss": 0.1242,
      "step": 410
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.20530878007411957,
      "learning_rate": 1.7995059348140165e-05,
      "loss": 0.1224,
      "step": 420
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.22110943496227264,
      "learning_rate": 1.6798115686809125e-05,
      "loss": 0.1226,
      "step": 430
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.27992355823516846,
      "learning_rate": 1.562189069707807e-05,
      "loss": 0.122,
      "step": 440
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2457825094461441,
      "learning_rate": 1.4469355625353198e-05,
      "loss": 0.1209,
      "step": 450
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.1279059648513794,
      "eval_runtime": 27.1974,
      "eval_samples_per_second": 7.28,
      "eval_steps_per_second": 0.919,
      "step": 450
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 0.21425889432430267,
      "learning_rate": 1.3343421875251888e-05,
      "loss": 0.1214,
      "step": 460
    },
    {
      "epoch": 2.088888888888889,
      "grad_norm": 0.2266298532485962,
      "learning_rate": 1.2246933653144385e-05,
      "loss": 0.1199,
      "step": 470
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.25944432616233826,
      "learning_rate": 1.1182660783441718e-05,
      "loss": 0.12,
      "step": 480
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 0.24655169248580933,
      "learning_rate": 1.0153291711778826e-05,
      "loss": 0.12,
      "step": 490
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.2261304408311844,
      "learning_rate": 9.161426713767574e-06,
      "loss": 0.1199,
      "step": 500
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 0.27332085371017456,
      "learning_rate": 8.209571326474896e-06,
      "loss": 0.1181,
      "step": 510
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 0.2767411172389984,
      "learning_rate": 7.300130019218687e-06,
      "loss": 0.1182,
      "step": 520
    },
    {
      "epoch": 2.3333333333333335,
      "eval_loss": 0.12678396701812744,
      "eval_runtime": 27.2579,
      "eval_samples_per_second": 7.264,
      "eval_steps_per_second": 0.917,
      "step": 525
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 0.24934571981430054,
      "learning_rate": 6.435400119669618e-06,
      "loss": 0.1189,
      "step": 530
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.26088985800743103,
      "learning_rate": 5.617566010602113e-06,
      "loss": 0.1173,
      "step": 540
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.26615697145462036,
      "learning_rate": 4.848693611953825e-06,
      "loss": 0.1191,
      "step": 550
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 0.24200181663036346,
      "learning_rate": 4.130725162132612e-06,
      "loss": 0.1184,
      "step": 560
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.22761929035186768,
      "learning_rate": 3.4654743117537524e-06,
      "loss": 0.1196,
      "step": 570
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 0.20321975648403168,
      "learning_rate": 2.8546215422010638e-06,
      "loss": 0.1189,
      "step": 580
    },
    {
      "epoch": 2.6222222222222222,
      "grad_norm": 0.24473293125629425,
      "learning_rate": 2.299709920585108e-06,
      "loss": 0.1177,
      "step": 590
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.23344701528549194,
      "learning_rate": 1.802141201821736e-06,
      "loss": 0.1194,
      "step": 600
    },
    {
      "epoch": 2.6666666666666665,
      "eval_loss": 0.1269737333059311,
      "eval_runtime": 27.2066,
      "eval_samples_per_second": 7.278,
      "eval_steps_per_second": 0.919,
      "step": 600
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 0.24903492629528046,
      "learning_rate": 1.3631722876775138e-06,
      "loss": 0.1174,
      "step": 610
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 0.20109473168849945,
      "learning_rate": 9.839120517267985e-07,
      "loss": 0.1188,
      "step": 620
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.21600577235221863,
      "learning_rate": 6.653185382408194e-07,
      "loss": 0.118,
      "step": 630
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 0.21374933421611786,
      "learning_rate": 4.0819654208472947e-07,
      "loss": 0.1183,
      "step": 640
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.2524474561214447,
      "learning_rate": 2.1319557573591108e-07,
      "loss": 0.1175,
      "step": 650
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.23109550774097443,
      "learning_rate": 8.080822855909831e-08,
      "loss": 0.1188,
      "step": 660
    },
    {
      "epoch": 2.977777777777778,
      "grad_norm": 0.25645267963409424,
      "learning_rate": 1.136892248288779e-08,
      "loss": 0.1185,
      "step": 670
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.12700125575065613,
      "eval_runtime": 27.2003,
      "eval_samples_per_second": 7.279,
      "eval_steps_per_second": 0.919,
      "step": 675
    }
  ],
  "logging_steps": 10,
  "max_steps": 675,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 75,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.869535547392e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
